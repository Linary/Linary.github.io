<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[深入学习Gremlin（15）：分支运算]]></title>
    <url>%2F2018%2F09%2F25%2Fhugegraph%2F%E6%B7%B1%E5%85%A5%E5%AD%A6%E4%B9%A0Gremlin%EF%BC%8815%EF%BC%89%EF%BC%9A%E5%88%86%E6%94%AF%E8%BF%90%E7%AE%97%2F</url>
    <content type="text"><![CDATA[第15期 Gremlin Steps： coalesce()、optional()、union() 本系列文章的Gremlin示例均在HugeGraph图数据库上执行，环境搭建可参考准备Gremlin执行环境，本文示例均以其中的“TinkerPop关系图”为初始数据。 上一期：深入学习Gremlin（14）：待添加 分支操作说明 coalesce: 可以接受任意数量的遍历器（traversal），按顺序执行，并返回第一个能产生输出的遍历器的结果； optional: 只能接受一个遍历器（traversal），如果该遍历器能产生一个结果，则返回该结果，否则返回调用optionalStep的元素本身。当连续使用.optional()时，如果在某一步返回了调用元素本身，则后续的.optional()不会继续执行； union: 可以接受任意数量的遍历器（traversal），并能够将各个遍历器的输出合并到一起； 实例讲解下面通过实例来深入理解每一个操作。 Step coalesce() 示例1： 12345// 按优先级寻找到顶点“HugeGraph”的以下边和邻接点，找到一个就停止// 1、“implements”出边和邻接点// 2、“supports”出边和邻接点// 3、“created”入边和邻接点g.V('3:HugeGraph').coalesce(outE('implements'), outE('supports'), inE('created')).inV().path().by('name').by(label) HugeGraph这三类边都是存在的，按照优先级，返回了“implements”出边和邻接点。 示例2： 12345// 按优先级寻找到顶点“HugeGraph”的以下边和邻接点，找到一个就停止（调换了示例1中的1和2的顺序）// 1、“supports”出边和邻接点// 2、“implements”出边和邻接点// 3、“created”入边和邻接点g.V('3:HugeGraph').coalesce(outE('supports'), outE('implements'), inE('created')).inV().path().by('name').by(label) 这次由于“supports”放在了“implements”的前面，所以返回了“supports”出边和邻接点。 自己动手比较一下outE(&#39;supports&#39;), outE(&#39;implements&#39;), inE(&#39;created&#39;)在.coalesce()中随意调换顺序的区别。 Step optional() 示例1： 12// 查找顶点"linary"的“created”出顶点，如果没有就返回"linary"自己g.V('linary').optional(out('created')) 示例2： 12// 查找顶点"linary"的“knows”出顶点，如果没有就返回"linary"自己g.V('linary').optional(out('knows')) 示例3： 12// 查找每个“person”顶点的出“knows”顶点，如果存在，然后以出“knows”顶点为起点，继续寻找其出“created”顶点，最后打印路径g.V().hasLabel('person').optional(out('knows').optional(out('created'))).path() 结果中的后面四个顶点因为没有出“knows”顶点，所以在第一步返回了自身后就停止了。 Step union() 示例1： 12// 寻找顶点“linary”的出“created”顶点，邻接“knows”顶点，并将结果合并g.V('linary').union(out('created'), both('knows')).path() 示例2： 12// 寻找顶点“HugeGraph”的入“created”顶点（创作者），出“implements”和出“supports”顶点，并将结果合并g.V('3:HugeGraph').union(__.in('created'), out('implements'), out('supports'), out('contains')).path() 顶点“HugeGraph”没有“contains”边，所以只打印出了其作者（入“created”），它实现的框架（出“implements”）和支持的特性（出“supports”）。 下一期：深入学习Gremlin（16）：待添加]]></content>
      <categories>
        <category>hugegraph</category>
      </categories>
      <tags>
        <tag>gremlin</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[深入学习Gremlin（11）：统计运算]]></title>
    <url>%2F2018%2F09%2F22%2Fhugegraph%2F%E6%B7%B1%E5%85%A5%E5%AD%A6%E4%B9%A0Gremlin%EF%BC%8811%EF%BC%89%EF%BC%9A%E7%BB%9F%E8%AE%A1%E8%BF%90%E7%AE%97%2F</url>
    <content type="text"><![CDATA[第11期 Gremlin Steps： sum()、max()、min()、mean() 本系列文章的Gremlin示例均在HugeGraph图数据库上执行，环境搭建可参考准备Gremlin执行环境，本文示例均以其中的“TinkerPop关系图”为初始数据。 上一期：深入学习Gremlin（10）：逻辑运算 统计运算说明Gremlin可以在Number类型的流（遍历器）上做简单的统计运算，包括计算总和、最大值、最小值、均值。 下面讲解实现上述功能的具体Step： sum()：将流上的所有的数字求和； max()：对流上的所有的数字求最大值； min()：对流上的所有的数字求最小值； mean()：将流上的所有的数字求均值； 这四种Step只能作用在Number类型的流上，在java里就是继承自java.lang.Number类。 实例讲解下面通过实例来深入理解每一个操作。 Step sum() 示例1： 12// 计算所有“person”的“age”的总和g.V().hasLabel('person').values('age').sum() 示例2： 12// 计算所有“person”的“created”出边数的总和g.V().hasLabel('person').map(outE('created').count()).sum() 试着输入g.V().hasLabel(&#39;person&#39;).map(outE(&#39;created&#39;).count())看看每个“person”的“created”出边数 Step max() 示例1： 12// 计算所有“person”的“age”中的最大值g.V().hasLabel('person').values('age').max() 示例2： 12// 计算所有“person”的“created”出边数的最大值g.V().hasLabel('person').map(outE('created').count()).max() Step min() 示例1： 12// 计算所有“person”的“age”中的最小值g.V().hasLabel('person').values('age').min() 示例2： 12// 计算所有“person”的“created”出边数的最小值g.V().hasLabel('person').map(outE('created').count()).min() Step mean() 示例1： 12// 计算所有“person”的“age”的均值g.V().hasLabel('person').values('age').mean() 示例2： 12// 计算所有“person”的“created”出边数的均值g.V().hasLabel('person').map(outE('created').count()).mean() 下一期：深入学习Gremlin（12）：待添加]]></content>
      <categories>
        <category>hugegraph</category>
      </categories>
      <tags>
        <tag>gremlin</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[深入学习Gremlin（7）：查询结果排序]]></title>
    <url>%2F2018%2F09%2F21%2Fhugegraph%2F%E6%B7%B1%E5%85%A5%E5%AD%A6%E4%B9%A0Gremlin%EF%BC%887%EF%BC%89%EF%BC%9A%E6%9F%A5%E8%AF%A2%E7%BB%93%E6%9E%9C%E6%8E%92%E5%BA%8F%2F</url>
    <content type="text"><![CDATA[第7期 Gremlin Steps： order()、by() 本系列文章的Gremlin示例均在HugeGraph图数据库上执行，环境搭建可参考准备Gremlin执行环境，本文示例均以其中的“TinkerPop关系图”为初始数据。 上一期：深入学习Gremlin（6）：循环操作 排序说明Gremlin允许对查询的结果进行排序输出，可以指定按某个属性的升序、降序或是随机序的方式输出。排序方式可以通过单独的order()或者order().by(...)指定，而by() step又有一些变种，下面分别讲解order()和order().by(...)的用法。 1.单独使用order() Step，一般用于遍历器中的元素是属性时： order()会将结果以升序输出； order()单独使用时，必须保证遍历器（traverser）中的元素是可排序的，在 java 里就是必须实现java.lang.Comparable接口，否则会抛出异常。 2.联合使用order().by(...) Step，传入排序方式，一般用于遍历器中的元素是属性时： order().by(incr): 将结果以升序输出，这也是默认的排序方式； order().by(decr): 将结果以降序输出； order().by(shuffle): 将结果以随机序输出，每次执行结果顺序都可能不一样。 使用 order().by(…) step 但是 by() 传递的仅是一个排序方式的参数时，也必须保证遍历器（traverser）中的元素是可排序的。 3.联合使用order().by(...) Step，传入属性和排序方式，用于遍历器中的元素是顶点或边时： order().by(key): 将结果按照元素属性key的值升序排列，与order().by(key, incr)等效； order().by(key, incr): 将结果按照元素属性key的值升序排列； order().by(key, decr): 将结果按照元素属性key的值降序排列； order().by(key, shuffle): 将结果按照元素属性key的值随机序排列，每次执行结果顺序都可能不一样。 by()step不是一个真正的step，而是一个“step modulator”，与此类似的还有as()和option()step。通过by()step可以为某些step添加traversal、function、comparator等，通常的使用方式是step().by()…by()，某些step只能添加一个by()，而有一些可以添加任意数量的by()step。 实例讲解 order()，使用默认的排序（升序）输出 12// 以默认排序输出所有顶点的"name"属性值g.V().values('name').order() order().by(incr)，指定以升序输出 12// 以升序输出所有顶点的"name"属性值g.V().values('name').order().by(incr) order().by(decr)，指定以降序输出 12// 以降序输出所有顶点的"name"属性值g.V().values('name').order().by(decr) order().by(shuffle)，指定以随机序输出 12// 以随机序输出所有顶点的"name"属性值g.V().values('name').order().by(shuffle) order().by(key)，按照元素属性key的值升序（默认）排列 12// 将"person"类型的顶点按照"age"升序（默认）排列输出g.V().hasLabel('person').order().by('age') 为了使”age”属性排列显示得更清晰，我们取出顶点的”age”属性 12// 将"person"类型的顶点按照"age"升序（默认）排列，并获取"age"属性g.V().hasLabel('person').order().by('age').values('age') order().by(key, incr)，按照元素属性key的值升序排列 12// 将"person"类型的顶点按照"age"升序排列，并获取"age"属性g.V().hasLabel('person').order().by('age', incr).values('age') order().by(key, desc)，按照元素属性key的值降序排列 12// 将"person"类型的顶点按照"age"降序排列输出，并获取"age"属性g.V().hasLabel('person').order().by('age', decr).values('age') order().by(key, shuffle)，按照元素属性key的值随机序排列 12// 将"person"类型的顶点按照"age"随机序排列输出，并获取"age"属性g.V().hasLabel('person').order().by('age', shuffle).values('age') 下一期：深入学习Gremlin（8）：数据分组与去重]]></content>
      <categories>
        <category>hugegraph</category>
      </categories>
      <tags>
        <tag>gremlin</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[深入学习Gremlin（10）：逻辑运算]]></title>
    <url>%2F2018%2F09%2F21%2Fhugegraph%2F%E6%B7%B1%E5%85%A5%E5%AD%A6%E4%B9%A0Gremlin%EF%BC%8810%EF%BC%89%EF%BC%9A%E9%80%BB%E8%BE%91%E8%BF%90%E7%AE%97%2F</url>
    <content type="text"><![CDATA[第10期 Gremlin Steps： is()、and()、or()、not() 本系列文章的Gremlin示例均在HugeGraph图数据库上执行，环境搭建可参考准备Gremlin执行环境，本文示例均以其中的“TinkerPop关系图”为初始数据。 上一期：深入学习Gremlin（9）：条件和过滤 逻辑运算说明Gremlin支持在遍历器上加上逻辑运算进行过滤，只有满足该逻辑条件的元素才会进入下一个遍历器中。 下面讲解实现上述功能的具体Step： is()：可以接受一个对象（能判断相等）或一个判断语句（如：P.gt()、P.lt()、P.inside()等），当接受的是对象时，原遍历器中的元素必须与对象相等才会保留；当接受的是判断语句时，原遍历器中的元素满足判断才会保留，其实接受一个对象相当于P.eq()； and()：可以接受任意数量的遍历器（traversal），原遍历器中的元素，只有在每个新遍历器中都能生成至少一个输出的情况下才会保留，相当于过滤器组合的与条件； or()：可以接受任意数量的遍历器（traversal），原遍历器中的元素，只要在全部新遍历器中能生成至少一个输出的情况下就会保留，相当于过滤器组合的或条件； not()：仅能接受一个遍历器（traversal），原遍历器中的元素，在新遍历器中能生成输出时会被移除，不能生成输出时则会保留，相当于过滤器的非条件。 这四种逻辑运算Step除了像一般的Step写法以外，and()和or()还可以放在where()中以中缀符的形式出现。 实例讲解下面通过实例来深入理解每一个操作。 Step is() 示例1： 12// 筛选出顶点属性“age”等于28的属性值，与`is(P.eq(28))`等效g.V().values('age').is(28) 当没有任何一个顶点的属性“age”为28时，输出为空。 示例2： 12// 筛选出顶点属性“age”大于等于28的属性值g.V().values('age').is(gte(28)) 示例3： 12// 筛选出顶点属性“age”属于区间（27，29）的属性值g.V().values('age').is(inside(27, 29)) P.inside(a, b)是左开右开区间（a，b） 示例4： 123// 筛选出由两个或两个以上的人参与创建（“created”）的顶点// 注意：这里筛选的是顶点g.V().where(__.in('created').count().is(gt(2))).values('name') where()Step可以接受一些过滤条件，在第10期会详细介绍。 示例5： 12// 筛选出有创建者（“created”）的年龄（“age”）在20～29之间的顶点g.V().where(__.in('created').values('age').is(between(20, 29))).values('name') Step and()，逻辑与 示例1： 12// 所有包含出边“supports”的顶点的名字“name”g.V().and(outE('supports')).values('name') 示例2： 12// 所有包含出边“supports”和“implements”的顶点的名字“name”g.V().and(outE('supports'), outE('implements')).values('name') 示例3： 12// 包含边“created”并且属性“age”为28的顶点的名字“name”g.V().and(outE('created'), values('age').is(28)).values('name') 示例4：“示例3”的中缀符写法 12345// 包含边“created”并且属性“age”为28的顶点的名字“name”g.V().where(outE('created') .and() .values('age').is(28)) .values('name') Step or()，逻辑或 示例1： 12// 所有包含出边“supports”的顶点的名字“name”g.V().or(outE('supports')).values('name') 只有一个条件时，and()与or()的效果一样的。 示例2： 12// 所有包含出边“supports”或“implements”的顶点的名字“name”g.V().or(outE('supports'), outE('implements')).values('name') 注意对比与g.V().and(outE(&#39;supports&#39;), outE(&#39;implements&#39;)).values(&#39;name&#39;)的差别 示例3： 12// 包含边“created”或属性“age”为28的顶点的名字“name”g.V().or(outE('created'), values('age').is(28)).values('name') 注意对比与g.V().and(outE(&#39;created&#39;), values(&#39;age&#39;).is(28)).values(&#39;name&#39;)的差别 示例4：“示例3”的中缀符写法 12345// 包含边“created”或属性“age”为28的顶点的名字“name”g.V().where(outE('created') .or() .values('age').is(28)) .values('name') Step not()，逻辑非 示例1： 12// 筛选出所有不是“person”的顶点的“label”g.V().not(hasLabel('person')).label() 示例2： 12// 筛选出所有包含不少于两条（大于等于两条）“created”边的“person”的名字“name”g.V().hasLabel('person').not(out('created').count().is(lt(2))).values('name') 综合运用目标：获取所有最多只有一条“created”边并且年龄不等于28的“person”顶点 写法1： 12345// 与（含有小于等于一条“created”边，年龄不等于28）g.V().hasLabel('person') .and(outE('created').count().is(lte(1)), values("age").is(P.not(P.eq(28)))) .values('name') 写法2： 12345// 非（或（含有多于一条“created”边，年龄等于28））g.V().hasLabel('person') .not(or(out('created').count().is(gt(1)), values('age').is(28))) .values('name') 下一期：深入学习Gremlin（11）：待添加]]></content>
      <categories>
        <category>hugegraph</category>
      </categories>
      <tags>
        <tag>gremlin</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[深入学习Gremlin（4）：图查询返回结果数限制]]></title>
    <url>%2F2018%2F09%2F14%2Fhugegraph%2F%E6%B7%B1%E5%85%A5%E5%AD%A6%E4%B9%A0Gremlin%EF%BC%884%EF%BC%89%EF%BC%9A%E5%9B%BE%E6%9F%A5%E8%AF%A2%E8%BF%94%E5%9B%9E%E7%BB%93%E6%9E%9C%E6%95%B0%E9%99%90%E5%88%B6%2F</url>
    <content type="text"><![CDATA[第4期 Gremlin Steps： count()、range()、limit()、tail()、skip() 本系列文章的Gremlin示例均在HugeGraph图数据库上执行，环境搭建可参考准备Gremlin执行环境，本文示例均以其中的“TinkerPop关系图”为初始数据。 上一期：深入学习Gremlin（3）：has条件过滤 图查询返回结果数限制说明 Gremlin能统计查询结果集中元素的个数，且允许从结果集中做范围截取。假设某个查询操作（如：g.V()）的结果集包含8个元素，我们可以从这8个元素中截取指定部分。主要包括： count(): 统计查询结果集中元素的个数； range(m, n): 指定下界和上界的截取，左闭右开。比如range(2, 5)能获取第2个到第4个元素（0作为首个元素，上界为-1时表示剩余全部）； limit(n): 下界固定为0，指定上界的截取，等效于range(0, n)，语义是“获取前n个元素”。比如limit(3)能获取前3个元素； tail(n): 上界固定为-1，指定下界的截取，等效于range(count - n, -1)，语义是“获取后n个元素”。比如tail(2)能获取最后的2个元素； skip(n): 上界固定为-1，指定下界的截取，等效于range(n, -1)，语义是“跳过前n个元素，获取剩余的元素”。比如skip(6)能跳过前6个元素，获取最后2个元素。 实例讲解下面通过实例来深入理解每一个操作。 Step count()：查询当前traverser中的元素的个数，元素可以是顶点、边、属性、路径等。 示例1：查询图中所有顶点的个数 1g.V().count() TinkerPop关系图的圆点就是顶点，总共12个。 示例2：查询图中类型为“人person”的顶点数 1g.V().hasLabel('person').count() TinkerPop关系图的绿点就是类型为“人person”的顶点，共7个。 示例3：查询图中所有的 “人创建created” 的边数 1g.V().hasLabel('person').outE('created').count() TinkerPop关系图的所有从绿点(person)出发并且连线上为“created”的边，共8个。 示例4：查询图中所有顶点的属性数 1g.V().properties().count() TinkerPop关系图的所有顶点的属性共47个，其中“人person”共有28个，“软件software”共有19个，大家可以自己数一数。 Step range()：限定查询返回的元素的范围，上下界表示元素的偏移量，左闭右开。下界以“0”作为第一个元素，上界为“-1”时表示取到最后的元素。 示例1：不加限制地查询所有类型为“人person”的顶点 1g.V().hasLabel('person').range(0, -1) 示例2：查询类型为“人person”的顶点中的第2个到第5个 1g.V().hasLabel('person').range(2, 5) 示例3：查询类型为“人person”的顶点中的第5个到最后一个 1g.V().hasLabel('person').range(5, -1) Step limit()：查询前“n”个元素，相当于range(0, n) 示例1：查询前两个顶点 1g.V().limit(2) 示例2：查询前三条边 1g.E().limit(3) Step tail()：与limit()相反，它查询的是后“n”个元素，相当于range(count - n, -1) 示例1：查询后两个顶点 1g.V().tail(2) 示例2：查询后三条边 1g.E().tail(3) Step skip()：跳过前“n”个元素，获取剩余的全部元素 skip()在HugeGraph中（tinkerpop 3.2.5）中尚不支持，下面给出代码以及预期的结果。 12// 跳过前5个，skip(5)等价于range(5, -1)g.V().hasLabel('person').skip(5) 下一期：深入学习Gremlin（5）：查询路径path]]></content>
      <categories>
        <category>hugegraph</category>
      </categories>
      <tags>
        <tag>gremlin</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[准备执行Gremlin的图形化环境]]></title>
    <url>%2F2018%2F09%2F07%2Fhugegraph%2F%E5%87%86%E5%A4%87%E6%89%A7%E8%A1%8CGremlin%E7%9A%84%E5%9B%BE%E5%BD%A2%E5%8C%96%E7%8E%AF%E5%A2%83%2F</url>
    <content type="text"><![CDATA[背景Gremlin是Apache TinkerPop框架下实现的图遍历语言，支持OLTP与OLAP，是目前图数据库领域主流的查询语言，可类比SQL语言之于关系型数据库。 HugeGraph是国内的一款开源图数据库，完全支持Gremlin语言。本文将讲述如何基于HugeGraph搭建一个执行Gremlin的图形化环境。 HugeGraph的github仓库下有很多子项目，我们这里只需要使用其中的两个：hugegraph和hugegraph-studio。 部署HugeGraphServer准备安装包方式一：源码编译打包进入hugegraph项目，克隆代码库 进入终端1$ git clone git@github.com:hugegraph/hugegraph.git 完成后会在当前目录下多出来一个hugegraph的子目录，不过这个目录里面的文件是源代码，我们需要编译打包才能生成可以运行包。 进入hugegraph目录，执行命令：12$ git checkout release-0.7$ mvn package -DskipTests 注意：一定要先切换分支，hugegraph主分支上版本已经升级到0.8.0了，但是studio似乎还没有升级，为避免踩坑我们还是使用已发布版。 经过一长串的控制台输出后，最后如果能看到BUILD SUCCESS表示打包成功。这时会在当前目录下多出来一个子目录hugegraph-0.7.4和一个压缩包hugegraph-0.7.4.tar.gz，这就是我们即将要使用可以运行的包。 本人有轻微强迫症，不喜欢源代码和二进制包放在一起，容易混淆，所以把hugegraph-0.7.4拷到上一层目录，然后删除源代码目录，这样上层目录又回归清爽了。123$ mv hugegraph-0.7.4 ../hugegraph-0.7.4$ cd ..$ rm -rf hugegraph 到这儿安装包就准备好了。不过，这样操作是需要你本地装了jdk、git和maven命令行工具的，如果你没有安装也没关系，我们还可以直接下载hugegraph官方的release包。 方法二：直接下载release包点击github代码的上面的导航releases 可以看到hugegraph目前有两个release，点击hugegraph-0.7.4.tar.gz就开始下载了。 下载完之后解压即可1$ tar -zxvf hugegraph-0.7.4.tar.gz 解压完之后能看到一个hugegraph-0.7.4目录，这个目录和用源码包打包生成的是一样的。 下面讲解如何配置参数。 配置参数虽然标题叫配置参数，但其实hugegraph的默认配置就已经能在大部分环境下直接使用了，不过还是说明一下几个重要的配置项。 进入hugegraph-0.7.4目录，修改HugeGraphServer提供服务的url (host + port)1234567891011121314$ vim conf/rest-server.properties# bind urlrestserver.url=http://127.0.0.1:8080# gremlin url to connectgremlinserver.url=http://127.0.0.1:8182# graphs list with pair NAME:CONF_PATHgraphs=[hugegraph:conf/hugegraph.properties]# authentication#auth.require_authentication=#auth.admin_token=#auth.user_tokens=[] restserver.url就是HugeGraphServer对外提供RESTful API服务的地址，host为127.0.0.1时只能在本机访问的，按需要修改其中的host和port部分即可。我这里由于studio也是准备在本地启动，8080端口也没有其他服务占用，所以不修改它。 graphs是可供连接的图名与配置项的键值对列表，hugegraph:conf/hugegraph.properties表示通过HugeGraphServer可以访问到一个名为hugegraph的图实例，该图的配置文件路径为conf/hugegraph.properties。我们可以不用去管图的配置文件，按需要修改图的名字即可。我这里仍然没有修改它。 初始化后端hugegraph启动服务之前是需要手动初始化后端的，不过大家也不要看到“手动”两个字就害怕，其实就是调一个命令的事。 1234567891011121314$ bin/init-store.shIniting HugeGraph Store...2018-09-07 16:02:12 1082 [main] [INFO ] com.baidu.hugegraph.cmd.InitStore [] - Init graph with config file: conf/hugegraph.properties2018-09-07 16:02:12 1201 [main] [INFO ] com.baidu.hugegraph.HugeGraph [] - Opening backend store &apos;rocksdb&apos; for graph &apos;hugegraph&apos;2018-09-07 16:02:12 1258 [main] [INFO ] com.baidu.hugegraph.backend.store.rocksdb.RocksDBStore [] - Opening RocksDB with data path: rocksdb-data/schema2018-09-07 16:02:12 1417 [main] [INFO ] com.baidu.hugegraph.backend.store.rocksdb.RocksDBStore [] - Failed to open RocksDB &apos;rocksdb-data/schema&apos; with database &apos;hugegraph&apos;, try to init CF later2018-09-07 16:02:12 1445 [main] [INFO ] com.baidu.hugegraph.backend.store.rocksdb.RocksDBStore [] - Opening RocksDB with data path: rocksdb-data/system2018-09-07 16:02:12 1450 [main] [INFO ] com.baidu.hugegraph.backend.store.rocksdb.RocksDBStore [] - Failed to open RocksDB &apos;rocksdb-data/system&apos; with database &apos;hugegraph&apos;, try to init CF later2018-09-07 16:02:12 1456 [main] [INFO ] com.baidu.hugegraph.backend.store.rocksdb.RocksDBStore [] - Opening RocksDB with data path: rocksdb-data/graph2018-09-07 16:02:12 1461 [main] [INFO ] com.baidu.hugegraph.backend.store.rocksdb.RocksDBStore [] - Failed to open RocksDB &apos;rocksdb-data/graph&apos; with database &apos;hugegraph&apos;, try to init CF later2018-09-07 16:02:12 1491 [main] [INFO ] com.baidu.hugegraph.backend.store.rocksdb.RocksDBStore [] - Store initialized: schema2018-09-07 16:02:12 1511 [main] [INFO ] com.baidu.hugegraph.backend.store.rocksdb.RocksDBStore [] - Store initialized: system2018-09-07 16:02:12 1543 [main] [INFO ] com.baidu.hugegraph.backend.store.rocksdb.RocksDBStore [] - Store initialized: graph2018-09-07 16:02:13 1804 [pool-3-thread-1] [INFO ] com.baidu.hugegraph.backend.Transaction [] - Clear cache on event &apos;store.init&apos; 这里可以看到，hugegraph初始化了rocksdb后端，那为什么是rocksdb而不是别的呢，其实就是上一步说的conf/hugegraph.properties中配置的。 1234567891011121314151617181920212223$ vim conf/hugegraph.properties# gremlin entrence to create graphgremlin.graph=com.baidu.hugegraph.HugeFactory# cache config#schema.cache_capacity=1048576#graph.cache_capacity=10485760#graph.cache_expire=600# schema illegal name template#schema.illegal_name_regex=\s+|~.*#vertex.default_label=vertexbackend=rocksdbserializer=binarystore=hugegraph# rocksdb backend config#rocksdb.data_path=/path/to/disk#rocksdb.wal_path=/path/to/disk... 其中backend=rocksdb就是设置后端为rocksdb的配置项。 其他的后端还包括：memory、cassandra、scylladb、hbase、mysql和palo。我们这里不用去管它，用默认的rocksdb即可。 初始化完成之后，会在当前目录下出现一个rocksdb-data的目录，这就是存放后端数据的地方，没事千万不要随意删它或移动它。 注意：初始化后端这个操作只需要在第一次启动服务前执行一次，不要每次起服务都执行。不过即使执行了也没关系，hugegraph检测到已经初始化过了会跳过。 启动服务终于到了启动服务了，同样也是一条命令 123$ bin/start-hugegraph.shStarting HugeGraphServer...Connecting to HugeGraphServer (http://127.0.0.1:8080/graphs)....OK 看到上面的OK就表示启动成功了，我们可以jps看一下进程。 12345$ jps...4101 HugeGraphServer4233 Jps... 如果还不放心，我们可以发个HTTP请求试试看。 12$ curl http://127.0.0.1:8080/graphs&#123;&quot;graphs&quot;:[&quot;hugegraph&quot;]&#125; 到这里HugeGraphServer的部署就完成了，接下来我们来部署HugeGraphStudio。 部署HugeGraphStudio步骤与部署HugeGraphServer大体类似，我们就不那么啰嗦了。 记得先返回最上层目录，避免目录嵌套在一起了。 准备安装包克隆代码库 12345678$ git clone git@github.com:hugegraph/hugegraph-studio.gitCloning into &apos;hugegraph-studio&apos;...mux_client_request_session: read from master failed: Broken piperemote: Counting objects: 326, done.remote: Compressing objects: 100% (189/189), done.remote: Total 326 (delta 115), reused 324 (delta 113), pack-reused 0Receiving objects: 100% (326/326), 1.60 MiB | 350.00 KiB/s, done.Resolving deltas: 100% (115/115), done. 编译打包 studio是一个包含前端的项目，使用react.js实现，自行打包的话需要安装npm、webpack等工具。 12$ cd hugegraph-studio$ mvn package -DskipTests studio打包的时间会稍长一点。 12345678910111213...[INFO] Reactor Summary:[INFO][INFO] hugegraph-studio ................................... SUCCESS [ 0.003 s][INFO] studio-api ......................................... SUCCESS [ 4.683 s][INFO] studio-dist ........................................ SUCCESS [01:42 min][INFO] ------------------------------------------------------------------------[INFO] BUILD SUCCESS[INFO] ------------------------------------------------------------------------[INFO] Total time: 01:47 min[INFO] Finished at: 2018-09-07T16:32:44+08:00[INFO] Final Memory: 34M/390M[INFO] ------------------------------------------------------------------------ 将打包好的目录拷到上一层，删除源码目录（纯个人喜好）。 123$ mv hugegraph-studio-0.7.0 ../$ cd ..$ rm -rf hugegraph-studio 至此，我的最上层目录就只剩下两个安装包，如下： 12$ lshugegraph-0.7.4 hugegraph-studio-0.7.0 配置参数进入hugegraph-studio-0.7.0目录，修改唯一的一个配置文件。 12345678910111213141516171819202122$ cd hugegraph-studio-0.7.0$ vim conf/hugegraph-studio.propertiesstudio.server.port=8088studio.server.host=localhostgraph.server.host=localhostgraph.server.port=8080graph.name=hugegraph# the directory name released by reactstudio.server.ui=ui# the file location of studio-api.warstudio.server.api.war=war/studio-api.war# default folder in your home directory, set to a non-empty value to overridedata.base_directory=~/.hugegraph-studioshow.limit.data=250show.limit.edge.total=1000show.limit.edge.increment=20# separator &apos;,&apos;gremlin.limit_suffix=[.V(),.E(),.hasLabel(STR),.hasLabel(NUM),.path()] 需要修改的参数是graph.server.host=localhost、graph.server.port=8080、graph.name=hugegraph。它们与HugeGraphServer的配置文件conf/rest-server.properties中的配置项对应，其中： graph.server.host=localhost与restserver.url=http://127.0.0.1:8080的host对应； graph.server.port=8080与的restserver.url=http://127.0.0.1:8080的port对应； graph.name=hugegraph与graphs=[hugegraph:conf/hugegraph.properties]的图名对应。 因为我之前并没有修改HugeGraphServer的配置文件conf/rest-server.properties，所以这里也不需要修改HugeGraphStudio的配置文件conf/hugegraph-studio.properties。 启动服务1$ bin/hugegraph-studio.sh studio的启动默认是不会放到后台的，所以我们会在控制台上看到一大串日志，在最底下看到如下日志表示启动成功： 12信息: Starting ProtocolHandler [http-nio-127.0.0.1-8088]16:56:24.507 [main] INFO com.baidu.hugegraph.studio.HugeGraphStudio ID: TS: - HugeGraphStudio is now running on: http://localhost:8088 然后我们按照提示，在浏览器中输入http://localhost:8088，就进入了studio的界面： 图中Gremlin下的框，就是我们输入gremlin语句进而操作hugegraph的入口了，下面我们给出一个例子。 创建关系图以下内容参考CSDN博客通过Gremlin语言构建关系图并进行图分析。 在输入框中输入以下代码以创建一个“TinkerPop关系图”： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869// PropertyKeygraph.schema().propertyKey(&quot;name&quot;).asText().ifNotExist().create()graph.schema().propertyKey(&quot;age&quot;).asInt().ifNotExist().create()graph.schema().propertyKey(&quot;addr&quot;).asText().ifNotExist().create()graph.schema().propertyKey(&quot;lang&quot;).asText().ifNotExist().create()graph.schema().propertyKey(&quot;tag&quot;).asText().ifNotExist().create()graph.schema().propertyKey(&quot;weight&quot;).asFloat().ifNotExist().create()// VertexLabelgraph.schema().vertexLabel(&quot;person&quot;).properties(&quot;name&quot;, &quot;age&quot;, &quot;addr&quot;, &quot;weight&quot;).useCustomizeStringId().ifNotExist().create()graph.schema().vertexLabel(&quot;software&quot;).properties(&quot;name&quot;, &quot;lang&quot;, &quot;tag&quot;, &quot;weight&quot;).primaryKeys(&quot;name&quot;).ifNotExist().create()graph.schema().vertexLabel(&quot;language&quot;).properties(&quot;name&quot;, &quot;lang&quot;, &quot;weight&quot;).primaryKeys(&quot;name&quot;).ifNotExist().create()// EdgeLabelgraph.schema().edgeLabel(&quot;knows&quot;).sourceLabel(&quot;person&quot;).targetLabel(&quot;person&quot;).properties(&quot;weight&quot;).ifNotExist().create()graph.schema().edgeLabel(&quot;created&quot;).sourceLabel(&quot;person&quot;).targetLabel(&quot;software&quot;).properties(&quot;weight&quot;).ifNotExist().create()graph.schema().edgeLabel(&quot;contains&quot;).sourceLabel(&quot;software&quot;).targetLabel(&quot;software&quot;).properties(&quot;weight&quot;).ifNotExist().create()graph.schema().edgeLabel(&quot;define&quot;).sourceLabel(&quot;software&quot;).targetLabel(&quot;language&quot;).properties(&quot;weight&quot;).ifNotExist().create()graph.schema().edgeLabel(&quot;implements&quot;).sourceLabel(&quot;software&quot;).targetLabel(&quot;software&quot;).properties(&quot;weight&quot;).ifNotExist().create()graph.schema().edgeLabel(&quot;supports&quot;).sourceLabel(&quot;software&quot;).targetLabel(&quot;language&quot;).properties(&quot;weight&quot;).ifNotExist().create()// TinkerPopokram = graph.addVertex(T.label, &quot;person&quot;, T.id, &quot;okram&quot;, &quot;name&quot;, &quot;Marko A. Rodriguez&quot;, &quot;age&quot;, 29, &quot;addr&quot;, &quot;Santa Fe, New Mexico&quot;, &quot;weight&quot;, 1)spmallette = graph.addVertex(T.label, &quot;person&quot;, T.id, &quot;spmallette&quot;, &quot;name&quot;, &quot;Stephen Mallette&quot;, &quot;age&quot;, 0, &quot;addr&quot;, &quot;&quot;, &quot;weight&quot;, 1)tinkerpop = graph.addVertex(T.label, &quot;software&quot;, &quot;name&quot;, &quot;TinkerPop&quot;, &quot;lang&quot;, &quot;java&quot;, &quot;tag&quot;, &quot;Graph computing framework&quot;, &quot;weight&quot;, 1)tinkergraph = graph.addVertex(T.label, &quot;software&quot;, &quot;name&quot;, &quot;TinkerGraph&quot;, &quot;lang&quot;, &quot;java&quot;, &quot;tag&quot;, &quot;In-memory property graph&quot;, &quot;weight&quot;, 1)gremlin = graph.addVertex(T.label, &quot;language&quot;, &quot;name&quot;, &quot;Gremlin&quot;, &quot;lang&quot;, &quot;groovy/python/javascript&quot;, &quot;weight&quot;, 1)okram.addEdge(&quot;created&quot;, tinkerpop, &quot;weight&quot;, 1)spmallette.addEdge(&quot;created&quot;, tinkerpop, &quot;weight&quot;, 1)okram.addEdge(&quot;knows&quot;, spmallette, &quot;weight&quot;, 1)tinkerpop.addEdge(&quot;define&quot;, gremlin, &quot;weight&quot;, 1)tinkerpop.addEdge(&quot;contains&quot;, tinkergraph, &quot;weight&quot;, 1)tinkergraph.addEdge(&quot;supports&quot;, gremlin, &quot;weight&quot;, 1)// Titandalaro = graph.addVertex(T.label, &quot;person&quot;, T.id, &quot;dalaro&quot;, &quot;name&quot;, &quot;Dan LaRocque &quot;, &quot;age&quot;, 0, &quot;addr&quot;, &quot;&quot;, &quot;weight&quot;, 1)mbroecheler = graph.addVertex(T.label, &quot;person&quot;, T.id, &quot;mbroecheler&quot;, &quot;name&quot;, &quot;Matthias Broecheler&quot;, &quot;age&quot;, 29, &quot;addr&quot;, &quot;San Francisco&quot;, &quot;weight&quot;, 1)titan = graph.addVertex(T.label, &quot;software&quot;, &quot;name&quot;, &quot;Titan&quot;, &quot;lang&quot;, &quot;java&quot;, &quot;tag&quot;, &quot;Graph Database&quot;, &quot;weight&quot;, 1)dalaro.addEdge(&quot;created&quot;, titan, &quot;weight&quot;, 1)mbroecheler.addEdge(&quot;created&quot;, titan, &quot;weight&quot;, 1)okram.addEdge(&quot;created&quot;, titan, &quot;weight&quot;, 1)dalaro.addEdge(&quot;knows&quot;, mbroecheler, &quot;weight&quot;, 1)titan.addEdge(&quot;implements&quot;, tinkerpop, &quot;weight&quot;, 1)titan.addEdge(&quot;supports&quot;, gremlin, &quot;weight&quot;, 1)// HugeGraphjaveme = graph.addVertex(T.label, &quot;person&quot;, T.id, &quot;javeme&quot;, &quot;name&quot;, &quot;Jermy Li&quot;, &quot;age&quot;, 29, &quot;addr&quot;, &quot;Beijing&quot;, &quot;weight&quot;, 1)zhoney = graph.addVertex(T.label, &quot;person&quot;, T.id, &quot;zhoney&quot;, &quot;name&quot;, &quot;Zhoney Zhang&quot;, &quot;age&quot;, 29, &quot;addr&quot;, &quot;Beijing&quot;, &quot;weight&quot;, 1)linary = graph.addVertex(T.label, &quot;person&quot;, T.id, &quot;linary&quot;, &quot;name&quot;, &quot;Linary Li&quot;, &quot;age&quot;, 28, &quot;addr&quot;, &quot;Wuhan. Hubei&quot;, &quot;weight&quot;, 1)hugegraph = graph.addVertex(T.label, &quot;software&quot;, &quot;name&quot;, &quot;HugeGraph&quot;, &quot;lang&quot;, &quot;java&quot;, &quot;tag&quot;, &quot;Graph Database&quot;, &quot;weight&quot;, 1)javeme.addEdge(&quot;created&quot;, hugegraph, &quot;weight&quot;, 1)zhoney.addEdge(&quot;created&quot;, hugegraph, &quot;weight&quot;, 1)linary.addEdge(&quot;created&quot;, hugegraph, &quot;weight&quot;, 1)javeme.addEdge(&quot;knows&quot;, zhoney, &quot;weight&quot;, 1)javeme.addEdge(&quot;knows&quot;, linary, &quot;weight&quot;, 1)hugegraph.addEdge(&quot;implements&quot;, tinkerpop, &quot;weight&quot;, 1)hugegraph.addEdge(&quot;supports&quot;, gremlin, &quot;weight&quot;, 1) 点击右上角的三角按钮，这样就创建出了一个图。 图查询在输入框中输入： 1g.V() 就能查出上面创建的图的所有顶点和边。 至此，执行Gremlin的图形化环境就已经搭建完成，后续就可以做各种各样炫酷的gremlin查询了。]]></content>
      <categories>
        <category>hugegraph</category>
      </categories>
      <tags>
        <tag>gremlin</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Netty源码剖析]]></title>
    <url>%2F2018%2F09%2F06%2Fnetty%2F</url>
    <content type="text"><![CDATA[Thread -&gt; NioEventLoop, Netty的发送机，主要包含两种线程，一种处理连接，一种发送接收数据。 while(true) -&gt; run() Socket -&gt; Channel IOBytes -&gt; ByteBuf // 就是一个供读写的数据链Logic Chain -&gt; Pipeline Logic -&gt; ChannelHandler Question: 1、socket在哪里创建 Netty服务端启动1、创建服务端Channel bind -&gt; initAndRegister -&gt; newChannel channelFactory.newChannel()通过反射创建Channel 1、newSocket通过JDK创建底层channel 2、NioServerScoektSocketChannelCOnfig（TCP参数配置） 3、AbstractNioChannel.configureBlocking(false) channelFactory 的clazz是在bootStrap的.channel(Class)传入的 2、初始化服务端Channel init 1、init() 2、setchannelOptions, ChannelAttrs 3、setChildOptions、ChildAttrs 4、config Handler 5、add ServerBootstrapAcceptor(一个特殊的Handler) 3、注册Selector 1、AbstractChannel.register(channel) channelAddedchannelRegistered 4、端口绑定 1、AbstractUnsafe.bind() 服务端启动核心路径总结 newChannel() -&gt; init() -&gt; register() -&gt; doBind() NioEventLoop三个问题： 默认Netty服务端起多少个线程？何时启动 Netty是如何解决jdk空轮询bug的 Netty如何保 NioEventLoop的创建new NioEventLoopGroup() NioEventLoop的启动NioEventLoop的执行逻辑]]></content>
      <categories>
        <category>网络通信</category>
      </categories>
      <tags>
        <tag>Netty，NIO</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[并发与高并发]]></title>
    <url>%2F2018%2F08%2F30%2Fconcurrent%2F</url>
    <content type="text"><![CDATA[并发与高并发的关注点 并发：多个线程操作相同的资源，保证程序线程安全，合理使用资源 高并发：服务能同时处理很多请求，提高程序性能 基础知识CPU多级缓存 为什么需要CPU缓存： 缓存存在的意义：时间一致性，空间一致性 缓存一致性（MESI）：用于保证多个CPU缓存之间缓存共享数据的一致性（没听懂） 乱序执行优化：处理器为提高运算速度而做出违背代码原有顺序的优化 J.U.C 之 AQS 组件CountDownLatch计数器，能阻塞（await）某些线程直到 CountDownLatch 的值变为 0，其他线程负责将 CountDownLatch 减 1（countDown）。 计数器只能使用一次。 Semaphore信号量，能控制一定数量线程的并发执行。 在执行业务代码前，调用acquire()获取一个许可，执行完之后，调用release()释放一个许可。 还允许尝试获取许可，尝试获取多个许可以及它们的超时版。 CyclicBarrier允许多个线程互相等待，到达全部准备好的状态。就像赛跑时所有人都要在起跑线上准备好，然后再一起开跑。 可以重置。 synchronized可重入锁，一个线程进去过一次后还可以再进去一次。 其实 synchronized 也是可重入锁。 自从 synchronized 引入了偏向锁，自旋锁之后，性能与 synchronized 差不多了。 StampedLockStampedLock 是 Java8 引入的一种新的所机制，简单的理解，可以认为它是读写锁的一个改进版本。读写锁虽然分离了读和写的功能，使得读与读之间可以完全并发，但是读和写之间依然是冲突的，读锁会完全阻塞写锁，它使用的依然是悲观的锁策略。如果有大量的读线程，他也有可能引起写线程的饥饿。而StampedLock 则提供了一种乐观的读策略，这种乐观策略的锁非常类似于无锁的操作，使得乐观锁完全不会阻塞写线程。 Fork/Join 框架并行流就是把一个内容分成多个数据块，并用不同的线程分别处理每个数据块的流。并行流的底层其实就是ForkJoin框架的一个实现。 Fork/Join框架：在必要的情况下，将一个大任务，进行拆分（fork） 成若干个子任务（拆到不能再拆，这里就是指我们制定的拆分的临界值），再将一个个小任务的结果进行join汇总。 Fork/Join采用“工作窃取模式”，当执行新的任务时他可以将其拆分成更小的任务执行，并将小任务加到线程队列中，然后再从一个随即线程中偷一个并把它加入自己的队列中。 就比如两个CPU上有不同的任务，这时候A已经执行完，B还有任务等待执行，这时候A就会将B队尾的任务偷过来，加入自己的队列中，对于传统的线程，ForkJoin更有效的利用的CPU资源！ BlockingQueueBlockingQueue 通常用于一个线程生产对象，而另外一个线程消费这些对象的场景。一个线程往里边放，另外一个线程从里边取。一个线程将会持续生产新对象并将其插入到队列之中，直到队列达到它所能容纳的临界点。也就是说，它是有限的。如果该阻塞队列到达了其临界点，负责生产的线程将会在往里边插入新对象时发生阻塞。它会一直处于阻塞之中，直到负责消费的线程从队列中拿走一个对象。负责消费的线程将会一直从该阻塞队列中拿出对象。如果消费线程尝试去从一个空的队列中提取对象的话，这个消费线程将会处于阻塞之中，直到一个生产线程把一个对象丢进队列。 直接提交队列：SynchronousQueue，没有容量，所以提交的任务不能保存，总是将任务交给空闲线程,如果没有空闲线程，就创建线程，一旦达到maximumPoolSize就执行拒绝策略 有界任务队列：ArrayBlockingQueue,当线程池的数量小于corePoolSize时，当有新的任务时，创建线程，达到corePoolSize后，则将任务存到ArrayBlockingQueue中，直到有界队列容量已满时，才可能会将线程数提升到corePoolSize之上。 无界队列：LinkedBlockingQueue,除非系统资源耗尽，否则不存在任务队列入队失败的情况，因此当线程数达到corePoolSize之后，就不会增加，有新的任务到来时，都会放到无界队列中。 优先任务队列：PriorityBlockingQueue是带有优先级的队列，特殊的无界队列,理论上来说不是先入先出的，是根据任务的优先级来确定执行顺序 DelayQueue：执行定时任务，将任务按延迟时间长短放入队列中，延迟时间最短的最先被执行，存放在队列头部的是延迟期满后保存时间最长的任务 LinkedTransferQueue：其实和SynchronousQueue类似，当生产者生产出产品后，当先去找是否有消费者，如果有消费者在等待资源，则直接调用transfer()方法将资源给消费者消费，而不会放入队列中。如果没有消费者等待，则当生产者调用transfer()方法时会阻塞，而调用其他的方法，如aput()则不会阻塞，会把资源放到队列中，因为put()方法只有在队列满的时候才会阻塞。适用于游戏服务器中，可以是并发时消息传递的效率更高 多线程并发最佳实践 使用本地变量 使用不可变类 最小化锁的作用域范围：S=1/(1-a + a/n) 使用线程池的 Executor，而不是直接 new Thread 执行 宁可使用同步也不要使用线程 wait 和 notify 使用 BlockingQueue 实现生产消费模式 使用并发集合而不是加了锁的同步集合 使用 Semaphore 创建有界的访问 宁可使用同步代码块，也不使用同步的方法 避免使用静态变量 高并发处理的思路及手段 扩容：水平扩容、垂直扩容 缓存：Redis、Memcache、Guava Cache等的介绍与使用 队列：kafka、RabbitMQ、RocketMQ等 应用拆分：服务化Dubbo与微服务Spring Cloud 限流：Guava RateLimiter，常用限流算法 服务降级与服务熔断：Hystrix 数据库切库、分库、分表 高可用：任务调度分布式elastic-job、主备curator的实现、监控报警机制 缓存浏览器 -&gt; 网络转发 -&gt; 服务 -&gt; 数据库 其实缓存可以出现在上述的各个环节中。 特征 命中率：命中数 /（命中数 + 未命中数） 最大元素（空间） 清空策略：FIFO、LFU、LRU、过期时间、随机等 缓存命中率影响因素 业务场景和业务需求 缓存的设计（粒度和策略） 缓存容量和基础设施 缓存分类和应用场景 本地缓存：编程实现（成员变量、局部变量、静态变量）、Guava Cache 分布式缓存：MemCache、Redis Guava Cache灵感来源于ConcurrentHashMap。 MemCache客户端：采用一致性哈希算法，把某个key的操作映射到固定机器上。 Redis远程内存数据库，支持数据持久化。]]></content>
      <categories>
        <category>并发</category>
      </categories>
      <tags>
        <tag>并发</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[基于JDK命令行工具的监控]]></title>
    <url>%2F2018%2F08%2F22%2FJVM-0%2F</url>
    <content type="text"><![CDATA[JVM 参数类型标准参数X参数 非标准化参数 -Xint：解释执行 -Xcomp：第一使用就编译成本地代码 -Xmixed：混合模式，JVM自己来决定是否编译成本地代码 XX参数 Boolean类型 格式：-XX:[+-]表示启动或禁用name属性 非Boolean类型 格式：-XX:=表示name属性的值是value 需要注意的是：-Xms和-Xmx虽然是以X打头，但是实际上是XX参数 -Xms等价于-XX:InitialHeapSize -Xmx等价于-XX:MaxHeapSize 查看JVM运行时的参数 -XX:+PrintFlagsInitial -XX:+PrintFlagsFinal -XX:+UnlockExpire =表示默认值，:=表示用户修改过后的值 1jinfo -flag MaxHeapSize &#123;pid&#125; jstat查看JVM统计信息类加载 -class 垃圾收集 -gc JIT编译 -compiler JVM的内存结构堆区： Young: S0 + S1 + Eden Old 非堆区（Metaspace）： CCS CodeCache jamp + MAT 实战内存溢出Java里面的内存溢出是说创建的对象一直不释放 堆内存溢出 构造一个List不停地添加普通对象 -Xmx32M, -Xms32M 非堆内存溢出 构造一个List不停地添加Class对象 -XX:MetaspaceSize=32M, -XX:MaxMetaspaceSize=32M 如何导出内存映像文件 内存溢出自动导出： 使用jmap命令手动导出：jamp -demp:format=b.file=heap.hprof MAT分析内存溢出官网下载，将上一步的文件导入。 jstack实战死循环与死锁监控远程普通Java进程远程启动 Java 进程时加上如下的参数，然后通过 JvisualM 就可以通过JMX连接进行监控了。 nohup java -Dcom.sun.management.jmxremote -Dcom.sun.management.jmxremote.port={port}-Dcom.sun.management.jmxremote.authenticate=false -Dcom.sun.management.jmxremote.ssl=false-Djava.net.preferIPv4Stack=true -Djava.rmi.server.hostname={ip} -jar {jar_name}.jar &amp; Btrace（可以考虑基于Btrace实现一个监控工具）Btrace 本质上就是一个拦截器，可以给 Java 进程动态添加拦截，它不需要修改原有的 Java 代码，通过一个独立进程提供监控。 默认只能在本地运行 生产环境下可以使用，但是被修改的字节码不会被还原 1btrace pid &#123;Btrace脚本&#125; 拦截方法 拦截时机 拦截this、参数、返回值 其他 拦截方法]]></content>
      <categories>
        <category>JVM</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[HBase学习]]></title>
    <url>%2F2018%2F08%2F20%2Fstudy-hbase%2F</url>
    <content type="text"><![CDATA[HBase中为什么要有Column FamilyHBase本身的设计目标是支持稀疏表，而稀疏表通常会有很多列，但是每一行有值的列又比较少。如果不使用Column Family的概念，那么有两种设计方案： 1.把所有列的数据放在一个文件中（也就是传统的按行存储）。那么当我们想要访问少数几个列的数据时，需要遍历每一行，读取整个表的数据，这样子是很低效的。 2.把每个列的数据单独分开存在一个文件中（按列存储）。那么当我们想要访问少数几个列的数据时，只需要读取对应的文件，不用读取整个表的数据，读取效率很高。然而，由于稀疏表通常会有很多列，这会导致文件数量特别多，这本身会影响文件系统的效率。 而Column Family的提出就是为了在上面两种方案中做一个折中。HBase中将一个Column Family中的列存在一起，而不同Column Family的数据则分开。由于在HBase中Column Family的数量通常很小，同时HBase建议把经常一起访问的比较类似的列放在同一个Column Family中，这样就可以在访问少数几个列时，只读取尽量少的数据。]]></content>
      <categories>
        <category>NoSQL</category>
      </categories>
      <tags>
        <tag>HBase</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Vue入门]]></title>
    <url>%2F2018%2F08%2F19%2Fstudy-vue%2F</url>
    <content type="text"><![CDATA[Vue 生命周期 动画 可以使用animate.css这个库添加很多炫酷的动画； 使用velocity.js库也可以添加动画（依靠js的钩子实现的动画）； 其他注意要点 子组件的data必须是一个函数 子组件不应该修改父组件传递进来的值]]></content>
      <categories>
        <category>前端</category>
      </categories>
      <tags>
        <tag>Vue.js</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[分布式存储系统]]></title>
    <url>%2F2018%2F08%2F06%2Fdistributed-storage%2F</url>
    <content type="text"><![CDATA[需要调研的分布式存储系统包括但不限于： 谷歌的GFS、BigTable、MegaStore和Spanner，阿里的TFS、Tair和OceanBase，Facebook的Haystack，亚马逊的Dynamo，Oracle的Mysql Sharding，PingCap 的TiDB等。]]></content>
      <categories>
        <category>分布式存储系统</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[内存数据库事务]]></title>
    <url>%2F2018%2F08%2F06%2Fmemory-db%2F</url>
    <content type="text"><![CDATA[前言 我们在使用数据库的时候，应该都体验过事务，我们对事务最直观的感受就是：一系列的操作要么全部生效，要么全部不生效，不会最后处于一种中间状态。其实这句话似乎只能体现事务的原子性，那其他几个特性呢？本文会先回顾一下事务的定义和ACID特性，再以一个具体的例子展示如何实现事务的四个特性。 事务定义所谓事务，它是一个操作序列，这些操作要么都执行，要么都不执行，它是一个不可分割的工作单位。 特性 原子性（Atomicity）：事务是一个不可再分割的工作单位，事务中的操作要么都发生，要么都不发生； 一致性（Consistency）：事务开始之前和事务结束以后，数据库的完整性约束没有被破坏。这是说数据库事务不能破坏关系数据的完整性以及业务逻辑上的一致性。 隔离性（Isolation）：多个事务并发访问时，事务之间是隔离的，一个事务不应该影响其它事务运行效果。 持久性（Durability）：事务完成以后，该事务所对数据库所作的更改便持久的保存在数据库之中，并不会被回滚。]]></content>
      <categories>
        <category>数据库</category>
      </categories>
      <tags>
        <tag>事务</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[自己实现一个轻量级的任务（线程）管理器]]></title>
    <url>%2F2018%2F07%2F23%2Fepoch-taskmanager%2F</url>
    <content type="text"><![CDATA[功能 允许自定义任务（继承任务基类），比如实时任务，延时任务，周期任务等，实时任务和延时任务都是执行一次，周期任务会反复执行。 允许定义任务链，依次顺序执行，上游任务失败了下游任务不会执行。但是不提供下游任务失败了上游任务回滚的能力。 允许提交，暂停（非必须），继续，重做和取消任务。 允许根据多种方式查询任务，比如查询根据任务Id查询，根据条件查询等，获取任务状态，进度等信息。 允许自定义任务的回调函数（成功、取消，超时，失败的响应）。 支持任务的持久化（非必须）。 关键点1、什么时候保存任务的信息？ 任务第一次提交给任务管理器后，保存。 任务成功或失败后，保存。 2、查询任务信息是每次都从后端查吗？ 任务创建后即加入到内存的容器中，在任务完成前都是从内存中查询，任务成功或者失败后（保存到数据库），从内存中删除任务的信息，而后的查询是从数据库查的。 3、当TaskManager退出时，应该扫描全部的任务，将内存中所有的任务（状态应该都是未完成）的快照都保存到数据库。以便于下次继续执行任务。 类结构设计1、Task 保存任务的静态信息，包括执行体（Callable），名称，类型，描述，参数，超时时间（可不设置）。 2、TaskTracker 保存任务的动态信息，包括进度，状态，运行时间等。]]></content>
      <categories>
        <category>调度管理</category>
      </categories>
      <tags>
        <tag>线程</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Guava Futures异步回调机制源码解析]]></title>
    <url>%2F2018%2F07%2F23%2Fguava-future%2F</url>
    <content type="text"><![CDATA[前言 最近本人在实现一个异步任务调度框架，不打算依赖于任何第三方包。在实现任务状态监听时遇到了一些困惑，于是想了解一下Guava中的ListenableFuture的实现方式。ListenableFuture实现非阻塞的方式是其提供了回调机制(机制)，下面将阐述该回调机制的实现，主要对Futures的addCallback方法源码进行剖析。 Guava Futures简介Google Guava框架的 com.google.common.util.concurrent包是并发相关的包，它是对JDK自带concurrent包中Future和线程池相关类的扩展，从而衍生出一些新类，并提供了更为广泛的功能。在项目中常用的该包中类如下所示： ListenableFuture：该接口扩展了Future接口，增加了addListener方法，该方法在给定的excutor上注册一个监听器，当计算完成时会马上调用该监听器。不能够确保监听器执行的顺序，但可以在计算完成时确保马上被调用。 FutureCallback：该接口提供了OnSuccess和onFailure方法。获取异步计算的结果并回调。 MoreExecutors：该类是final类型的工具类，提供了很多静态方法。例如listeningDecorator方法初始化ListeningExecutorService方法，使用此实例submit方法即可初始化ListenableFuture对象。 ListenableFutureTask：该类是一个适配器，可以将其它Future适配成ListenableFuture。 ListeningExecutorService：该类是对ExecutorService的扩展，重写了ExecutorService类中的submit方法，并返回ListenableFuture对象。 JdkFutureAdapters：该类扩展了FutureTask类并实现ListenableFuture接口，增加了addListener方法。 Futures：该类提供和很多实用的静态方法以供使用。 Futures.addCallback方法源码剖析下面将模拟异步发送请求，并对请求结果进行(回调)监听。这里使用Spring框架提供的AsyncRestTemplate，来发送http请求，并获取一个org.springframework.util.concurrent.ListenableFuture对象，此时的对象是spring框架中的ListenableFuture对象。由于org.springframework.util.concurrent包中只提供了最基本的监听功能，没有其它额外功能，这里将其转化成Guava中的ListenableFuture，用到了JdkFutureAdapters这个适配器类。(以下源码来自guava-18.0.jar) 12345678910111213141516AsyncRestTemplate tp = new AsyncRestTemplate();org.springframework.util.concurrent.ListenableFuture&lt;ResponseEntity&lt;Object&gt;&gt; response = tp .getForEntity("http://blog.csdn.net/pistolove", Object.class);ListenableFuture&lt;ResponseEntity&lt;Object&gt;&gt; listenInPoolThread = JdkFutureAdapters.listenInPoolThread(response);Futures.addCallback(listenInPoolThread, new FutureCallback&lt;Object&gt;() &#123; @Override public void onSuccess(Object result) &#123; System.err.println(result.getClass()); System.err.printf("success", result); &#125; @Override public void onFailure(Throwable t) &#123; System.out.printf("failure"); &#125;&#125;); Futures的addCallback方法通过传入ListenableFuture和FutureCallback（一般情况FutureCallback实现为内部类）来实现回调机制。 1234//com.google.common.util.concurrent.Futurespublic static &lt;V&gt; void addCallback(ListenableFuture&lt;V&gt; future, FutureCallback&lt;? super V&gt; callback) &#123; addCallback(future, callback, directExecutor());&#125; 在addCallback方法中，我们发现多了一个 directExecutor()方法，这里的 directExecutor()方法返回的是一个枚举类型的线程池，这样做的目的是提高性能，而线程池中的execute方法实质执行的是所的传入参数Runnable 的run方法，可以把这里的线程池看作一个”架子”。 123456789101112//创建一个单实例的线程 接口需要显著的性能开销 提高性能public static Executor directExecutor() &#123; return DirectExecutor.INSTANCE;&#125;/** See &#123;@link #directExecutor&#125; for behavioral notes. */private enum DirectExecutor implements Executor &#123; INSTANCE; @Override public void execute(Runnable command) &#123; command.run(); &#125;&#125; 在具体的addCallback方法中，首先判断FutureCallback是否为空，然后创建一个线程，这个线程的run方法中会获取到一个value值，这里的value值即为http请求的结果，然后将value值传入FutureCallback的onSuccess方法，然后我们就可以在onSuccess方法中执行业务逻辑了。这个线程是如何执行的呢？继续往下看，发现调用了ListenableFuture的addListener方法，将刚才创建的线程和上一步创建的枚举线程池传入。 123456789101112131415161718192021222324252627282930313233//增加回调 public static &lt;V&gt; void addCallback(final ListenableFuture&lt;V&gt; future, final FutureCallback&lt;? super V&gt; callback, Executor executor) &#123; Preconditions.checkNotNull(callback); //每一个future进来都会创建一个独立的线程运行 Runnable callbackListener = new Runnable() &#123; @Override public void run() &#123; final V value; try &#123; // TODO(user): (Before Guava release), validate that this // is the thing for IE. //这里是真正阻塞的地方，直到获取到请求结果 value = getUninterruptibly(future); &#125; catch (ExecutionException e) &#123; callback.onFailure(e.getCause()); return; &#125; catch (RuntimeException e) &#123; callback.onFailure(e); return; &#125; catch (Error e) &#123; callback.onFailure(e); return; &#125; //调用callback的onSuccess方法返回结果 callback.onSuccess(value); &#125; &#125;; //增加监听，其中executor只提供了一个架子的线程池 future.addListener(callbackListener, executor); &#125; 在addListener方法中，将待执行的任务和枚举型线程池加入ExecutionList中，ExecutionList的本质是一个链表，将这些任务链接起来。具体可参考下方代码注释。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748@Override public void addListener(Runnable listener, Executor exec) &#123; //将监听任务和线程池加入到执行列表中 executionList.add(listener, exec); //This allows us to only start up a thread waiting on the delegate future when the first listener is added. //When a listener is first added, we run a task that will wait for the delegate to finish, and when it is done will run the listeners. //这允许我们启动一个线程来等待future当第一个监听器被加入的时候 //当第一个监听器被加入，我们将启动一个任务等待future完成，一旦当前的future完成后将会执行监听器 //判断是否有监听器加入 if (hasListeners.compareAndSet(false, true)) &#123; //如果当前的future完成则立即执行监听列表中的监听器,执行完成后返回 if (delegate.isDone()) &#123; // If the delegate is already done, run the execution list // immediately on the current thread. //执行监听列表中的监听任务 executionList.execute(); return; &#125; //如果当前的future没有完成，则启动线程池执行其中的任务，阻塞等待直到有一个future完成，然后执行监听器列表中的监听器 adapterExecutor.execute(new Runnable() &#123; @Override public void run() &#123; try &#123; /* * Threads from our private pool are never interrupted. Threads * from a user-supplied executor might be, but... what can we do? * This is another reason to return a proper ListenableFuture * instead of using listenInPoolThread. */ getUninterruptibly(delegate); &#125; catch (Error e) &#123; throw e; &#125; catch (Throwable e) &#123; // ExecutionException / CancellationException / RuntimeException // The task is done, run the listeners. &#125; //执行链表中的任务 executionList.execute(); &#125; &#125;); &#125; &#125; &#125; 在ExecutionList的add方法中，判断是否执行完成，如果没有执行完成，则放入待执行的链表中并返回，否则调用executeListener方法执行任务，在executeListener方法中，我们发现执行的是线程池的execute方法，而execute方法实质的是调用了任务线程的run方法，这样最终会调用OnSuccess方法获取到执行结果。 12345678910111213141516171819202122232425//将任务放入ExecutionList中 public void add(Runnable runnable, Executor executor) &#123; // Fail fast on a null. We throw NPE here because the contract of // Executor states that it throws NPE on null listener, so we propagate // that contract up into the add method as well. Preconditions.checkNotNull(runnable, "Runnable was null."); Preconditions.checkNotNull(executor, "Executor was null."); // Lock while we check state. We must maintain the lock while adding the // new pair so that another thread can't run the list out from under us. // We only add to the list if we have not yet started execution. //判断是否执行完成，如果没有执行完成，则放入待执行的链表中 synchronized (this) &#123; if (!executed) &#123; runnables = new RunnableExecutorPair(runnable, executor, runnables); return; &#125; &#125; // Execute the runnable immediately. Because of scheduling this may end up // getting called before some of the previously added runnables, but we're // OK with that. If we want to change the contract to guarantee ordering // among runnables we'd have to modify the logic here to allow it. //执行监听 executeListener(runnable, executor); &#125; execute方法是执行任务链表中的任务，由于先加入的任务会依次排列在链表的末尾，所以需要将链表翻转。然后从链表头开始依次取出任务执行并放入枚举线程池中执行。 1234567891011121314151617181920212223242526272829303132333435363738394041//执行监听链表中的任务 public void execute() &#123; // Lock while we update our state so the add method above will finish adding // any listeners before we start to run them. //创建临时变量保存列表，并将成员变量置空让垃圾回收 RunnableExecutorPair list; synchronized (this) &#123; if (executed) &#123; return; &#125; executed = true; list = runnables; runnables = null; // allow GC to free listeners even if this stays around for a while. &#125; // If we succeeded then list holds all the runnables we to execute. The pairs in the stack are // in the opposite order from how they were added so we need to reverse the list to fulfill our // contract. // This is somewhat annoying, but turns out to be very fast in practice. Alternatively, we // could drop the contract on the method that enforces this queue like behavior since depending // on it is likely to be a bug anyway. // N.B. All writes to the list and the next pointers must have happened before the above // synchronized block, so we can iterate the list without the lock held here. //因为先加入的监听任务会在连边的末尾，所以需要将链表翻转 RunnableExecutorPair reversedList = null; while (list != null) &#123; RunnableExecutorPair tmp = list; list = list.next; tmp.next = reversedList; reversedList = tmp; &#125; //从链表头中依次取出监听任务执行 while (reversedList != null) &#123; executeListener(reversedList.runnable, reversedList.executor); reversedList = reversedList.next; &#125; &#125; 在上文中，可以发现每当对一个ListenerFuture增加回调时，都会创建一个线程，而这个线程的run方法中会获取一个value值，这个value值就是通过下面的getUninterruptibly方法获取到的，我们可以发现在方法中调用了while进行阻塞，一直等到future获取到结果，即发送的http请求获取到数据后才会终止并返回。可以看出，回调机制将获取结果中的阻塞分散开来，即使现在有100个线程在并发地发送http请求，那么也只是创建了100个独立的线程并行阻塞，那么运行的总时间则会是这100个线程中最长的时间，而不是100个线程的时间相加，这样就实现了异步非阻塞机制。 123456789101112131415161718//用while阻塞直到获取到结果 public static &lt;V&gt; V getUninterruptibly(Future&lt;V&gt; future) throws ExecutionException &#123; boolean interrupted = false; try &#123; while (true) &#123; try &#123; return future.get(); &#125; catch (InterruptedException e) &#123; interrupted = true; &#125; &#125; &#125; finally &#123; if (interrupted) &#123; Thread.currentThread().interrupt(); &#125; &#125; &#125; 这里实质上执行了线程的run方法，并进行阻塞。 12345678910111213//执行监听器，调用线程池的execute方法，这里线程池并没有提供额外的功能，只提供了执行架子，实际上执行的是监听任务runnable的run方法 //而在监听任务的run方法中，会阻塞获取请求结果，请求完成后回调，已达到异步执行的效果 private static void executeListener(Runnable runnable, Executor executor) &#123; try &#123; executor.execute(runnable); &#125; catch (RuntimeException e) &#123; // Log it and keep going, bad runnable and/or executor. Don't // punish the other runnables if we're given a bad one. We only // catch RuntimeException because we want Errors to propagate up. log.log(Level.SEVERE, "RuntimeException while executing runnable " + runnable + " with executor " + executor, e); &#125; &#125; 使用JdkFutureAdaoter适配Spring中的ListenableFuture达到异步调用的结果。在future.get方法中到底阻塞在什么地方呢？通过调试发现最后调用的是BasicFuture中的阻塞方法。详情见下方源码和中文注释，这里不累赘。 123456FutureAdapter: //这里的get方法会调用BasicFuture中的get方法进行阻塞，直到获取到结果 @Override public T get() throws InterruptedException, ExecutionException &#123; return adaptInternal(this.adaptee.get()); &#125; 12345678BasicFuture: //在这里会判断当前future是否执行完成，如果没有完成则会等待，一旦执行完成则返回结果。 public synchronized T get() throws InterruptedException, ExecutionException &#123; while (!this.completed) &#123; wait(); &#125; return getResult(); &#125; 123456789101112131415161718192021222324252627282930313233FutureAdapter: //这里通过判断状态是否success，如果success则返回成功，如果new, 则阻塞等待结果直到返回，然后改变状态。 @SuppressWarnings("unchecked") final T adaptInternal(S adapteeResult) throws ExecutionException &#123; synchronized (this.mutex) &#123; switch (this.state) &#123; case SUCCESS: return (T) this.result; case FAILURE: throw (ExecutionException) this.result; case NEW: try &#123; T adapted = adapt(adapteeResult); this.result = adapted; this.state = State.SUCCESS; return adapted; &#125; catch (ExecutionException ex) &#123; this.result = ex; this.state = State.FAILURE; throw ex; &#125; catch (Throwable ex) &#123; ExecutionException execEx = new ExecutionException(ex); this.result = execEx; this.state = State.FAILURE; throw execEx; &#125; default: throw new IllegalStateException(); &#125; &#125; &#125; 123456789101112131415//这个方法判断 public boolean completed(final T result) &#123; synchronized(this) &#123; if (this.completed) &#123; return false; &#125; this.completed = true; this.result = result; notifyAll(); &#125; if (this.callback != null) &#123; this.callback.completed(result); &#125; return true; &#125; 总结本文主要剖析了Futures.callback方法的源码，我们只需要一个ListenableFuture的实例，就可以使用该方法来实现回调机制。假设在我们的主线程中，有n个子方法要发送http请求，这时，我们可以创建n个ListenableFuture，对这n个ListenableFuture增加监听，这n个请求就是异步且非阻塞的，这样不但主线程不会阻塞，而且会大大减少总的响应时间。那Futures.callback是如何实现并发的呢？通过源码，我们发现，对于每一个ListenableFuture，都会创建一个独立的线程对其进行监听，也就是这n个ListenableFuture对应着n个独立的线程，而在每一个独立的线程中会各自调用Future.get方法阻塞。]]></content>
      <categories>
        <category>网络通信</category>
      </categories>
      <tags>
        <tag>async</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[自己动手实现RPC框架（一）]]></title>
    <url>%2F2018%2F07%2F10%2Fepoch-rpc%2Fepoch-rpc-1%2F</url>
    <content type="text"><![CDATA[前言 RPC的概念看过很多，我的理解是：调用端获取到服务（网络方法）提供者的网络地址，并把方法调用的参数通过网络传递给提供者，提供者监听并获取到参数后，调用自己的方法，再把执行结果通过网络回传给调用端。这样站在调用端的角度看，就像是调用自己的本地方法一样，只不过慢一些而已。 RPC经典的架构图如下： RPC架构中可以认为有四个角色，消费者（Consumer），提供者（Provider），注册中心（Registry）和监控中心（Monitor）。以前在同一系统里的方法调用者因为网络的存在，变成了消费者，被调的方法成为了提供者。而所谓的注册中心，其实就是为了让消费者实时的去感知提供者的存在，去告诉消费者它对应的提供者的地址。监控中心，其实在整个过程中，它并不是一定要存在，只是它可以做统计，做一些数据分析，提供整个系统的可用性，健壮性。 好了，我们先简单分析一下 Registry / Consumer / Provider / Monitor 这四个角色的定义和每个角色如何各司其职，相互协作完成这整个过程的。 下面从两个方面进行分析，一是每个角色在网络的定位，二是每个角色所要完成的职责。 Registry注册中心简述： 注册中心可以有多个，都是无状态的，每个注册中心之间信息不交互 从网络的角度来说，它都是server端，它不需要主动地连接其他的任何实例，只需要像一个地主一样等待别人来连接 消费者随机选择注册中心集群中的任何实例建立长连接，提供者与注册中心中的每一个实例都建立长连接 职责(与其说职责，还不如说代码要实现的功能)： 接收服务提供者的服务注册信息，接收到信息之后，发送ACK信息给服务提供者，否则服务提供者重新发送注册信息 接收消费者的订阅信息，并把它订阅的结果返回给消费者 如果注册信息变更，会主动通知订阅变更信息的消费者，注册信息的变更包括服务提供者下线，服务被人工降级，或者服务提供者的地址变更 持久化一些服务信息，例如某些服务管理员审核过了，则该服务重新注册后则不需要再审核，再例如，某个服务负载均衡的策略被管理员设置为轮询，那么下次它在注册的时候，则就是轮询，而不是默认的负载策略 Provider提供者简述： 提供者是一个精神分裂的病人，它在网络上（可以更加明确地说是站在Netty的角度上）饰演两个角色： 它是客户端，需要去连接Registry，发送注册信息，它也需要去连接monitor端，去发送一些调用的统计信息 它也是服务端，需要作为server端等待Consumer去连接，连接成功后调用服务 职责： 将自己的信息，提供的接口信息编织成注册信息发送给registry端 能够动态去调自己的方法，可以通过反射，cglib等一些方法去调用自己提供的那些方法 提供服务降级等服务，如果当某些服务调用的失败率高于限定值的时候，可以有一个对应的mock方法，提供降级服务 限流服务，限流的方式有很多种，也有很多实现方式，最简单的就是控制调用次数，比如100w次，其实简单的就是控制单位时间的调用次数，防止业务洪流冲垮服务 统计活动，将一些调用信息统计好发送给Monitor端 Consumer消费者简述： 它也是有两个网络角色，不过并不是精神分裂，它都是作为网络的客户端存在，一它需要去连接registry去获取到订阅信息，二是它需要主动去连接provider端去调用服务 职责： 去向Registry端订阅服务，拿到registry端返回的结果，这个结果也就是provider的网络地址，先建立TCP的长连接，可能是多个地址，因为提供某个服务的可能有多个提供者 当开始系统主动调用该服务的时候，拿到刚才建立的连接的集合，根据某个方法，是随意还是轮询，获取到其中的一个连接，发送方法入参，等待响应 当注册中心发送某个服务的调用的负载策略发生变化过，发送信息给consumer，consumer需要做相应的变更 Monitor监控者简述： 这个与整个系统是没有任何直接的关系的，实现方式也是多样的，可以与上面一样建立长连接，接收每个角色统计的信息，然后展示给用户，可以使用MQ,使用消息队列，每个角色把自己统计的信息放到队列中，Monitor去消费这些信息，这样做的好处就是解耦，如果monitor宕了，不影响服务 大体的RPC的流程稍微理了一下，接下来我们就来一一去实现这些功能~]]></content>
      <categories>
        <category>分布式服务</category>
      </categories>
      <tags>
        <tag>rpc</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[自己动手实现RPC框架（二）之项目结构]]></title>
    <url>%2F2018%2F07%2F10%2Fepoch-rpc%2Fepoch-rpc-2%2F</url>
    <content type="text"><![CDATA[前言 暂时还没法确定到底是什么样的包结构，等写完的时候再来填充这里。]]></content>
      <categories>
        <category>分布式服务</category>
      </categories>
      <tags>
        <tag>rpc</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Git常用操作记录]]></title>
    <url>%2F2018%2F07%2F05%2Fgit-operation%2F</url>
    <content type="text"><![CDATA[将本地仓库和github仓库关联起来 12git remote add github git@github.com:liningrui/study-rpc.gitgit pull 再查看所有分支就可以看到github远端分支的信息了 1git branch -av 删除github远端的分支 1git push github :travis 这样就删除了travis分支 创建orphan分支，名为source 1git checkout --orphan source 注：如果不提交东西，这个分支实际上没有创建 查看某个指定文件的提交历史记录 1git log -p filePath 这样就先显示指定文件的每一次提交及修改信息（diff），但是不能显示文件改名前的修改，要注意第一次提交是不是改文件名 查看某一个分支创建的时间 1git reflog show --date=iso branch 最下面的应该就是该分支的创建时间 修改提交历史 1、找到要修改的commit id及其前一个commit id 1git rebase -i --before-commit-id 弹出来的一堆以 pick 开头的 commit id 和 commit message 的行，将第一行（也允许修改多行）的 pick 修改为 edit，然后保存退出vim，git 会在标记的 commit 停下来，然后我们可以做相应的修改，再执行 12git commit -a --amendgit rebase --continue 这时 git 会打印 rebasing(progress/total)，中间很有可能会产生冲突，解决好冲突后执行 12git add filegit rebase --continue 一直往下走，遇到冲突就重复这一步，直到走完全部的提交，这样就实现了修改历史。]]></content>
      <categories>
        <category>开发工具</category>
      </categories>
      <tags>
        <tag>Git</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[单例模式]]></title>
    <url>%2F2018%2F07%2F05%2Fjava-singleton%2F</url>
    <content type="text"><![CDATA[前言 在GoF的23种设计模式中，单例模式是比较简单的一种。然而，有时候越是简单的东西越容易出现问题。下面就单例设计模式详细的探讨一下。 所谓单例模式，简单来说，就是在整个应用中保证类只有一个实例存在。这个类的实例只提供了一个全局变量，用处相当广泛，比如保存全局数据，实现全局性的操作等。 最简单的实现首先，能够想到的最简单的实现是，把类的构造函数写成private的，从而保证别的类不能实例化此类，然后在类中提供一个静态的实例并能够返回给使用者。这样，使用者就可以通过这个引用使用到这个类的实例了。 123456789101112public class SingletonClass &#123; private static SingletonClass instance = new SingletonClass(); public static SingletonClass getInstance() &#123; return instance; &#125; private SingletonClass() &#123; &#125;&#125; 外部使用者如果需要使用SingletonClass的实例，只能通过getInstance()方法，并且它的构造方法是private的，这样就保证了只能有一个对象存在。 性能优化上面的代码虽然简单，但是有一个问题—-无论这个类是否被使用，都会创建一个instance对象。如果这个创建过程很耗时，比如需要连接10000次jdbc实例连接或者10000多个模版实例，并且这个类还并不一定会被使用，那么这个创建过程就是无用的。 为了解决这个问题，我们想到了新的解决方案： 123456789101112131415public class SingletonClass &#123; private static SingletonClass instance = null; public static SingletonClass getInstance() &#123; if (instance == null) &#123; instance = new SingletonClass(); &#125; return instance; &#125; private SingletonClass() &#123; &#125;&#125; 代码的变化有一处—-把instance初始化为null，直到第一次使用的时候通过判断是否为null来创建对象。 我们来想象一下这个过程。要使用SingletonClass，调用getInstance()方法。第一次的时候发现instance是null，然后就新建一个对象，返回出去；第二次再使用的时候，因为这个instance是static的，所以已经不是null了，因此不会再创建对象，直接将其返回。 这个过程就称为lazy loaded，也就是延迟加载—-直到使用的时候才进行加载。 同步上面的代码很清楚，也很简单。然而就像那句名言：”80%的错误都是由20%代码优化引起的”。单线程下，这段代码没有什么问题，可是如果是多线程，麻烦就来了。我们来分析一下： 线程1希望使用SingletonClass，调用getInstance()方法。因为是第一次调用，1就发现instance是null的，于是它开始创建实例，就在这个时候，CPU发生时间片切换(或者被抢夺执行)，线程2开始执行，它要使用SingletonClass，调用getInstance()方法，同样检测到instance是null—-注意，这是在1检测完之后切换的，也就是说1并没有来得及创建对象—-因此2开始创建。2创建完成后，cpu切换到1继续执行，因为它已经检测完了，所以1不会再检测一遍，它会直接创建对象。这样，线程1和2各自拥有一个SingletonClass的对象—-单例失败！解决的方法也很简单，那就是加锁： 12345678910111213141516public class SingletonClass &#123; private static SingletonClass instance = null; public synchronized static SingletonClass getInstance() &#123; if(instance == null) &#123; instance = new SingletonClass(); &#125; return instance; &#125; private SingletonClass() &#123; &#125;&#125; 又是性能问题上面的代码又是很清楚很简单的，然而，简单的东西往往不够理想。理想的东西往往不够简单，这就是生活。这段代码毫无疑问存在性能的问题—-synchronized修饰的同步块可是要比一般的代码段慢上几倍的！如果存在很多次getInstance()的调用，那性能问题就不得不考虑了！ 让我们来分析一下，究竟是整个方法都必须加锁，还是仅仅其中某一句加锁就足够了？我们为什么要加锁呢？分析一下出现lazy loaded的那种情形的原因。原因就是检测null的操作和创建对象的操作分离了。如果这两个操作能够原子地进行，那么单例就已经保证了。于是，我们开始修改代码： 1234567891011121314151617181920public class SingletonClass &#123; private static SingletonClass instance = null; public static SingletonClass getInstance() &#123; if (instance == null) &#123; synchronized (SingletonClass.class) &#123; if (instance == null) &#123; instance = new SingletonClass(); &#125; &#125; &#125; return instance; &#125; private SingletonClass() &#123; &#125;&#125; 还有问题吗？首先判断instance是不是为null，如果为null，加锁初始化；如果不为null，直接返回instance。 这就是double-checked locking设计实现单例模式。但是还有问题。 在Java虚拟机规范中试图定义一种Java内存模型（Java Memory Model，JMM）来屏蔽各个硬件平台和操作系统的内存访问差异，以实现让Java程序在各种平台下都能达到一致的内存访问效果。那么Java内存模型规定了哪些东西呢，它定义了程序中变量的访问规则，往大一点说是定义了程序执行的次序。注意，为了获得较好的执行性能，Java内存模型并没有限制执行引擎使用处理器的寄存器或者高速缓存来提升指令执行速度，也没有限制编译器对指令进行重排序。也就是说，在java内存模型中，也会存在缓存一致性问题和指令重排序的问题。 下面来想一下，创建一个变量需要哪些步骤呢？一个是申请一块内存，调用构造方法进行初始化操作，另一个是分配一个指针指向这块内存。这两个操作谁在前谁在后呢？JMM规范并没有规定。（可能重排序）那么就存在这么一种情况，JVM是先开辟出一块内存，然后把指针指向这块内存，最后调用构造方法进行初始化。 线程1开始创建SingletonClass的实例，此时线程B调用了getInstance()方法，首先判断instance是否为null。按照我们上面所说的内存模型，1已经把instance指向了那块内存，只是还没有调用构造方法，因此2检测到instance不为null，于是直接把instance返回了—-问题出现了，尽管instance不为null，但它并没有构造完成，就像一套房子已经给了你钥匙，但你并不能住进去，因为里面还是毛坯房。此时，如果2在1将instance构造完成之前就是用了这个实例，程序就会出现错误了！ 最终解决方案在JDK 5之后，Java使用了新的内存模型。volatile关键字有了明确的语义—-在JDK1.5之前，volatile是个关键字，但是并没有明确的规定其用途—-被volatile修饰的写变量不能和之前的读写代码调整，读变量不能和之后的读写代码调整！因此，只要我们简单的把instance加上volatile关键字就可以了。 1234567891011121314151617181920public class SingletonClass &#123; private volatile static SingletonClass instance = null; public static SingletonClass getInstance() &#123; if (instance == null) &#123; synchronized (SingletonClass.class) &#123; if(instance == null) &#123; instance = new SingletonClass(); &#125; &#125; &#125; return instance; &#125; private SingletonClass() &#123; &#125;&#125;]]></content>
      <categories>
        <category>编程语言</category>
      </categories>
      <tags>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[自己动手实现RPC框架]]></title>
    <url>%2F2018%2F07%2F05%2Fepoch-rpc%2Fepoch-rpc-0%2F</url>
    <content type="text"><![CDATA[前言 RPC的文章看了不少，但是始终感觉似懂非懂，古人说的”纸上得来终觉浅，绝知此事要躬行”还是很有道理的。所以我希望通过一个真正的项目，来加深对RPC的认识。 这应该会是一个系列文章，至少在我动笔的这一刻是有非常强烈的意愿完成它的。 主要参考CSDN博客一起写RPC框架开篇说明 2018-09-03续，果不其然，还是因为诸多事情耽搁了。 今天又看了一些RPC的文章，发现黄勇老师的轻量级分布式 RPC 框架写的非常清晰易懂。于是整理出一些关键点出来，方便自己实现。 编写RPC框架的步骤如下： 编写服务接口 编写服务接口的实现类 配置服务端 启动服务器并发布服务 实现服务注册 实现 RPC 服务器 配置客户端 实现服务发现 实现 RPC 代理 发送 RPC 请求 注册中心的职责核心的职责如下： 服务提供者向其发送它提供的服务的一些基本信息，并完成注册 服务消费者订阅服务 服务提供者下线的时候，实时通知服务消费者某个服务下线 除此之外，还有一些锦上添花但在真实的业务中必须得有的功能，比如： 服务审核，这是服务治理最最简单的操作了，因为某个服务提供者上线之后，都是需要审核的，如果不审核，可能会造成很多不必要的麻烦，有可能有些开发小新，不小心把开发环境的服务向线上服务注册，如果不审核，直接通过的话，就会造成线上接口调用线下服务的尴尬局面 负载策略的记录，比如默认是随机加权策略，如果管理者希望改成加权轮询的策略，需要通知服务消费者，访问策略的改变 手动改变某个服务的访问权重，比如某个服务默认负重是50，（最大100）的时候，但是此时这个服务实例所在的机器压力不大的时候，而其他该服务实例压力很大的时候，可以适当的增加该服务的访问权重，所以我们可以在注册中心修改它的负重，然后通知服务消费者，这样就可以动态的修改负重了 一些持久化的操作，因为注册中心是无状态的，假如某个注册中心实例重启之后，以前的一些审核信息，修改的访问策略信息就会消失，这样就会需要用户重新一一审核，这是很麻烦的，所以需要将这些信息落地，持久化到硬盘，然后每次重启注册中心实例的时候，去读取这些信息 基于ZooKeeper的注册中心节点树结构如下： 计划（暂定） 2018-07-08 架构设计，功能（细节）设计 2018-07-15 网络传输模型，序列化部分 2018-07-22 服务端框架 2018-07-29 客户端框架 2018-08-06 负载均衡 2018-08-13 服务降级 2018-08-20 测试与优化]]></content>
      <categories>
        <category>分布式服务</category>
      </categories>
      <tags>
        <tag>rpc</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Mac 下安装 jekyll]]></title>
    <url>%2F2018%2F07%2F04%2Fmac-install-jekyll%2F</url>
    <content type="text"><![CDATA[Mac 下安装 jekyll1sudo gem install jekyll 输入密码，但还是会提示没有写权限 12ERROR: While executing gem ... (Gem::FilePermissionError) You don&apos;t have write permissions for the /usr/bin directory. 原因是 Apple在OS X El Capitan中全面启用了名为System Integrity Protection (SIP)的系统完整性保护技术。受此影响，大部分系统文件即使在root用户下也无法直接进行修改。 升级ruby（推荐） 安装RVM1curl -L get.rvm.io | bash -s stable 出现异常 12345678910111213141516171819gpg: Signature made 一 7/ 2 03:41:26 2018 CSTgpg: using RSA key 62C9E5F4DA300D94AC36166BE206C29FBF04FF17gpg: Can&apos;t check signature: No public keyWarning, RVM 1.26.0 introduces signed releases and automated check of signatures when GPG software found. Assuming you trust Michal Papis import the mpapis public key (downloading the signatures).GPG signature verification failed for &apos;/Users/liningrui/.rvm/archives/rvm-1.29.4.tgz&apos; - &apos;https://github.com/rvm/rvm/releases/download/1.29.4/1.29.4.tar.gz.asc&apos;! Try to install GPG v2 and then fetch the public key: gpg2 --recv-keys 409B6B1796C275462A1703113804BB82D39DC0E3or if it fails: command curl -sSL https://rvm.io/mpapis.asc | gpg2 --import -the key can be compared with: https://rvm.io/mpapis.asc https://keybase.io/mpapisNOTE: GPG version 2.1.17 have a bug which cause failures during fetching keys from remote server. Please downgrade or upgrade to newer version (if available) or use the second method described above. 你是因为我本地安装了gpg，但是却没有它的公钥，所以我们需要先接受公钥到本地。 1gpg2 --recv-keys 409B6B1796C275462A1703113804BB82D39DC0E3 然后再执行上述命令，就应该Ok了。 1234567891011121314151617gpg: Signature made 一 7/ 2 03:41:26 2018 CSTgpg: using RSA key 62C9E5F4DA300D94AC36166BE206C29FBF04FF17gpg: Good signature from &quot;Michal Papis (RVM signing) &lt;mpapis@gmail.com&gt;&quot; [unknown]gpg: aka &quot;Michal Papis &lt;michal.papis@toptal.com&gt;&quot; [unknown]gpg: aka &quot;[jpeg image of size 5015]&quot; [unknown]gpg: WARNING: This key is not certified with a trusted signature!gpg: There is no indication that the signature belongs to the owner.Primary key fingerprint: 409B 6B17 96C2 7546 2A17 0311 3804 BB82 D39D C0E3 Subkey fingerprint: 62C9 E5F4 DA30 0D94 AC36 166B E206 C29F BF04 FF17GPG verified &apos;/Users/liningrui/.rvm/archives/rvm-1.29.4.tgz&apos;Installing RVM to /Users/liningrui/.rvm/ Adding rvm PATH line to /Users/liningrui/.profile /Users/liningrui/.mkshrc /Users/liningrui/.bashrc /Users/liningrui/.zshrc. Adding rvm loading line to /Users/liningrui/.profile /Users/liningrui/.bash_profile /Users/liningrui/.zlogin.Installation of RVM in /Users/liningrui/.rvm/ is almost complete: * To start using RVM you need to run `source /Users/liningrui/.rvm/scripts/rvm` in all your open shell windows, in rare cases you need to reopen all shell windows. 它提示说要使用RVM需要将rvm添加到环境变量中。 12source /Users/liningrui/.rvm/scripts/rvmrvm -v 列出所有可用的ruby版本 1rvm list known 安装最新版本的ruby（以2.5.1为例） 1rvm install 2.5.1 安装jekyll1gem install jekyll 安装完成后，cd到项目根目录，使用以下命令即可运行jekyll环境，通过 localhost:4000 即可访问。 1jekyll serve 提示1Dependency Error: Yikes! It looks like you don&apos;t have jekyll-paginate or one of its dependencies installed. In order to use Jekyll as currently configured, you&apos;ll need to install this gem. The full error message from Ruby is: &apos;cannot load such file -- jekyll-paginate&apos; If you run into trouble, you can find helpful resources at https://jekyllrb.com/help/! 安装即可 1gem install jekyll-paginate 接下来就可以开始github pages之路了～ 参考： https://www.cnblogs.com/kaiye/archive/2013/04/24/3039345.html https://blog.csdn.net/andanlan/article/details/50061775]]></content>
  </entry>
  <entry>
    <title><![CDATA[阻塞非阻塞与同步异步的区别]]></title>
    <url>%2F2018%2F07%2F04%2Fnetwork-io%2F</url>
    <content type="text"><![CDATA[我认为同步、异步、阻塞、非阻塞，是分3个层次的： CPU层次； 线程层次； 程序员感知层次。 这几个概念之所以容易混淆，是因为没有分清楚是在哪个层次进行讨论。 CPU层次在CPU层次，或者说操作系统进行IO和任务调度的层次，现代操作系统通常使用异步非阻塞方式进行IO（有少部分IO可能会使用同步非阻塞轮询），即发出IO请求之后，并不等待IO操作完成，而是继续执行下面的指令（非阻塞），IO操作和CPU指令互不干扰（异步），最后通过中断的方式来通知IO操作完成结果。 线程层次在线程层次，或者说操作系统调度单元的层次，操作系统为了减轻程序员的思考负担，将底层的异步非阻塞的IO方式进行封装，把相关系统调用（如read，write等）以同步的方式展现出来。然而，同步阻塞的IO会使线程挂起，同步非阻塞的IO会消耗CPU资源在轮询上。为了解决这一问题，就有3种思路： 多线程（同步阻塞）； IO多路复用（select，poll，epoll）（同步非阻塞，严格地来讲，是把阻塞点改变了位置）； 直接暴露出异步的IO接口，如kernel-aio和IOCP（异步非阻塞）。 程序员感知层次在Linux中，上面提到的第2种思路用得比较广泛，也是比较理想的解决方案。然而，直接使用select之类的接口，依然比较复杂，所以各种库和框架百花齐放，都试图对IO多路复用进行封装。此时，库和框架提供的API又可以选择是以同步的方式还是异步的方式来展现。如python的asyncio库中，就通过协程，提供了同步阻塞式的API；如node.js中，就通过回调函数，提供了异步非阻塞式的API。 总结因此，我们在讨论同步、异步、阻塞、非阻塞时，必须先明确是在哪个层次进行讨论。比如node.js，我们可以说她在程序员感知层次提供了异步非阻塞的API，也可以说在Linux下，她在线程层次以同步非阻塞的epoll来实现。]]></content>
      <categories>
        <category>网络通信</category>
      </categories>
      <tags>
        <tag>NIO，IO</tag>
      </tags>
  </entry>
</search>
